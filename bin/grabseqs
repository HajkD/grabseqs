#!/usr/bin/env python

import requests, argparse, sys, os, time, json
from subprocess import call

# Test with SRP159164 (single) or ERP020555 (single and paired)

def get_sra_acc_metadata(pacc, save = False, loc = ''):
	"""
	Function to get list of SRA accession numbers from a particular project.
	Takes project accession number `pacc` and returns a list of SRA 
	accession numbers. Optional arguments to `save` metadata .csv in a specified
	`loc`ation.
	Originally featured in: https://github.com/louiejtaylor/hisss
	"""
	metadata = requests.get("http://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?save=efetch&db=sra&rettype=runinfo&term="+pacc)
	if save:
		f = open(os.path.join(loc,pacc+".tsv"), 'w')
		f.write(metadata.text)
		f.close()
	lines = [l.split(',') for l in metadata.text.split("\n")]
	run_col = lines[0].index("Run")
	run_list = [l[run_col] for l in lines[1:] if len(l[run_col]) > 0]

	return run_list

def run_fasterq_dump(acc, retries = 0, threads = 1, loc='', force=False):
	"""
	Helper function to run fasterq-dump to grab a particular `acc`ession,
	with support for a particular number of `retries`. Can use multiple
	`threads`.
	"""
	skip = False
	retcode = 1
	while retries >= 0:
		if not force:
			existing = [f for f in os.listdir(loc) if f.endswith('fastq.gz')]
			for f in existing:
				if (acc + '.' in f) or (acc + '_' in f):
					print("found file: " + f + "  matching " + acc + ", skipping download. Pass -f to force download")
					skip = True
					break
		if not skip:
			print("downloading " + acc + " using fasterq-dump")
			cmd = ["fasterq-dump", "-e", str(threads), "-f", "-3"]
			if loc != "":
				cmd = cmd + ['-O', loc]	
			cmd = cmd + [acc]
			retcode = call(cmd)
			if retcode == 0:
				rgzip = call(["pigz -f -p "+ str(threads) + ' ' + os.path.join(loc,acc+'*'+'fastq')], shell=True)
				break
			else:
				time.sleep(60) #TODO?: user-modifiable
				retries -= 1
		return retcode

def get_mgrast_acc_metadata(pacc, save = False, loc = ''):
	"""
	Function to get list of MG-RAST sample accession numbers from a particular 
	project. Takes project accession number `pacc` and returns a list of mgm
	accession numbers. Optional arguments to `save` metadata .csv in a specified
	`loc`ation.
	"""
	metadata_json = json.loads(requests.get("http://api.metagenomics.anl.gov/metadata/export/"+pacc).text)
	sample_list = []
	for sample in metadata_json["samples"]:
		sample_list.append(sample["libraries"][0]["data"]["metagenome_id"]["value"]) #metadata: ["data"]
	#TODO: Save metadata detail
	return sample_list

def download_mgrast_sample(acc, retries = 0, threads = 1, loc='', force=False):
	"""
	Helper function to download original (uploaded) MG-RAST `acc`ession,
	with support for a particular number of `retries`. Can use multiple
	`threads` with pigz (if data are not already compressed on arrival).
	"""
	#"http://api.metagenomics.anl.gov/download/"  # returns json object with sample info

	#"?file=50.1" # 50.1 is R1, 50.2 (if it exists) is R2

	wget_cmd = ["wget", "-O", os.path.join(loc,acc+".fastw"), "http://api.metagenomics.anl.gov/download/"+acc+"?file=050.1"]
	#TODO
	retcode = call(wget_cmd) #TODO: figure out how to parse if not found
	return retcode

if __name__ == "__main__":

	# Top-level parser
	parser = argparse.ArgumentParser(prog="grabseqs",
		 description='Download metagenomic sequences from public datasets.')
	parser.add_argument('--version', '-v', action='version', version='%(prog)s 0.1.1')
	subpa = parser.add_subparsers(help='repositories available')

	# Parser for SRA data
	parser_sra = subpa.add_parser('sra', help="download from SRA")
	parser_sra.add_argument('id', type=str, nargs='+', 
				help="One or more BioProject, ERR/SRR or ERP/SRP number(s)")
	parser_sra.add_argument('-o', dest="outdir", type=str, default="",
				help="directory in which to save output. created if it doesn't exist")
	parser_sra.add_argument('-m', dest="metadata", action="store_true",
				help="save SRA metadata")
	parser_sra.add_argument('-f', dest="force", action="store_true",
				help = "force re-download of files")
	parser_sra.add_argument('-t',dest="threads", type=int, default=1,
				help="threads to use (for fasterq-dump/pigz)")
	parser_sra.add_argument('-r',dest="retries", type=int, default=0,
				help="number of times to retry download")

	# Parser for MG-RAST data
	parser_rast = subpa.add_parser('mgrast', help="download from MG-RAST")
	parser_rast.add_argument('rastid', type=str, nargs='+', 
				help="One or more MG-RAST project identifiers (mgp####)")
	parser_rast.add_argument('-o', dest="outdir", type=str, default="",
				help="directory in which to save output. created if it doesn't exist")
	parser_rast.add_argument('-m', dest="metadata", action="store_true",
				help="save metadata")
	parser_rast.add_argument('-f', dest="force", action="store_true",
				help = "force re-download of files")
	parser_rast.add_argument('-t',dest="threads", type=int, default=1,
				help="threads to use (for pigz)")
	parser_rast.add_argument('-r',dest="retries", type=int, default=0,
				help="number of times to retry download")

	args = parser.parse_args()

	# Make output directories if they don't exist
	try:
		if args.outdir != "":
			if not os.path.exists(args.outdir):
				os.makedirs(args.outdir)
	except AttributeError: # No args were provided
		print("No arguments found, run `grabseqs -h` or  `grabseqs sra -h` for help")
		sys.exit(0)
	try:
		if args.rastid:
			for rast_proj in args.rastid:
				target_list = get_mgrast_acc_metadata(rast_proj, args.metadata, args.outdir)
				print(target_list)
				for target in target_list:
					download_mgrast_sample(target, args.retries, args.threads, args.outdir, args.force)
	except AttributeError:
		for sra_identifier in args.id:
			acclist = get_sra_acc_metadata(sra_identifier, args.metadata, args.outdir)

			for acc in acclist:
				run_fasterq_dump(acc, args.retries, args.threads, args.outdir, args.force)


