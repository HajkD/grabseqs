#!/usr/bin/env python

import requests, argparse, sys, os, time, json
from subprocess import call

# Test with SRP159164 (single) or ERP020555 (single and paired)

def get_sra_acc_metadata(pacc, save = False, loc = ''):
	"""
	Function to get list of SRA accession numbers from a particular project.
	Takes project accession number `pacc` and returns a list of SRA 
	accession numbers. Optional arguments to `save` metadata .csv in a specified
	`loc`ation.
	Originally featured in: https://github.com/louiejtaylor/hisss
	"""
	metadata = requests.get("http://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?save=efetch&db=sra&rettype=runinfo&term="+pacc)
	if save:
		f = open(os.path.join(loc,pacc+".tsv"), 'w')
		f.write(metadata.text)
		f.close()
	lines = [l.split(',') for l in metadata.text.split("\n")]
	run_col = lines[0].index("Run")
	run_list = [l[run_col] for l in lines[1:] if len(l[run_col]) > 0]

	return run_list

def run_fasterq_dump(acc, retries = 0, threads = 1, loc='', force=False):
	"""
	Helper function to run fasterq-dump to grab a particular `acc`ession,
	with support for a particular number of `retries`. Can use multiple
	`threads`.
	"""
	skip = False
	retcode = 1
	while retries >= 0:
		if not force:
			existing = [f for f in os.listdir(loc) if f.endswith('fastq.gz')]
			for f in existing:
				if (acc + '.' in f) or (acc + '_' in f):
					print("found file: " + f + "  matching " + acc + ", skipping download. Pass -f to force download")
				skip = True
					break
		if not skip:
			print("downloading " + acc + " using fasterq-dump")
			cmd = ["fasterq-dump", "-e", str(threads), "-f", "-3"]
			if loc != "":
				cmd = cmd + ['-O', loc]	
			cmd = cmd + [acc]
			retcode = call(cmd)
			if retcode == 0:
				rgzip = call(["pigz -f -p "+ str(threads) + ' ' + os.path.join(loc,acc+'*'+'fastq')], shell=True)
				break
			else:
				time.sleep(60) #TODO?: user-modifiable
				retries -= 1
		return retcode

def get_mgrast_acc_metadata(pacc, save = False, loc = ''):
	"""
	Function to get list of MG-RAST sample accession numbers from a particular 
	project. Takes project accession number `pacc` and returns a list of mgm
	accession numbers. Optional arguments to `save` metadata .csv in a specified
	`loc`ation.
	"""
	if pacc[:3] == "mgm":
		return [pacc]
	elif pacc[:3] != "mgp":
		raise NameError("Unknown prefix: " + pacc[:3] + ". Should be 'mgm' or 'mgp'.")
	metadata_json = json.loads(requests.get("http://api.metagenomics.anl.gov/metadata/export/"+pacc).text)
	sample_list = []
	for sample in metadata_json["samples"]:
		sample_list.append(sample["libraries"][0]["data"]["metagenome_id"]["value"]) #metadata: ["data"]
	#TODO: Save metadata detail
	return sample_list

def download_mgrast_sample(acc, retries = 0, threads = 1, loc='', force=False):
	"""
	Helper function to download original (uploaded) MG-RAST `acc`ession,
	with support for a particular number of `retries`. Can use multiple
	`threads` with pigz (if data are not already compressed on arrival).
	"""
	read_stages = ["050.1", "050.2"] # R1 and R2 (if paired)

	metadata_json = json.loads(requests.get("http://api.metagenomics.anl.gov/download/"+acc).text)
	stages_to_grab = []
	for stage in metadata_json["data"]:
		if stage["file_id"] in read_stages:
			stages_to_grab.append(stage["file_id"])
	stages_to_grab = sorted(stages_to_grab) # sort because json

	if len(stages_to_grab) == 0:
		raise Exception("No sequences found for accession: "+acc)
	else:
		if len(stages_to_grab) == 1:
			fext = [""] # unpaired, no ext
		else:
			fext = ["_"+str(i+1) for i in range(len(stages_to_grab))] # paired

	fa_paths = [os.path.join(loc,acc+ext+".fasta") for ext in fext]
	fq_paths = [os.path.join(loc,acc+ext+".fastq") for ext in fext]

	for i in range(len(fa_paths)):
		fa_path = fa_paths[i]
		fq_path = fq_paths[i]
		wget_cmd = ["wget", "-O", fa_path, "http://api.metagenomics.anl.gov/download/"+acc+"?file="+stages_to_grab[i]]
		retcode = call(wget_cmd) #TODO: figure out how to parse if not found
		seq = -1
		fq = open(fq_path, 'w')
		with open(fa_path) as f: # convert .fasta to .fastq
			for line in f:
				if line[0] == '>':
					if seq == -1:
						fq.write('@'+line[1:])
					else:
						fq.write(seq+'\n')
						fq.write('+\n')	
						fq.write('I'*len(seq)+'\n')
						fq.write('@'+line[1:])
					seq = ''
				else:
					seq += line.strip()
		fq.close()
		retcode = call(["rm "+fa_path], shell=True) # get rid of old fasta
		rzip = call(["pigz -f -p "+ str(threads) + ' ' + fq_path], shell=True)

	return retcode

if __name__ == "__main__":

	# Top-level parser
	parser = argparse.ArgumentParser(prog="grabseqs",
		 description='Download metagenomic sequences from public datasets.')
	parser.add_argument('--version', '-v', action='version', version='%(prog)s 0.1.1')
	subpa = parser.add_subparsers(help='repositories available')

	# Parser for SRA data
	parser_sra = subpa.add_parser('sra', help="download from SRA")
	parser_sra.add_argument('id', type=str, nargs='+', 
				help="One or more BioProject, ERR/SRR or ERP/SRP number(s)")
	parser_sra.add_argument('-o', dest="outdir", type=str, default="",
				help="directory in which to save output. created if it doesn't exist")
	parser_sra.add_argument('-m', dest="metadata", action="store_true",
				help="save SRA metadata")
	parser_sra.add_argument('-f', dest="force", action="store_true",
				help = "force re-download of files")
	parser_sra.add_argument('-t',dest="threads", type=int, default=1,
				help="threads to use (for fasterq-dump/pigz)")
	parser_sra.add_argument('-r',dest="retries", type=int, default=0,
				help="number of times to retry download")

	# Parser for MG-RAST data
	parser_rast = subpa.add_parser('mgrast', help="download from MG-RAST")
	parser_rast.add_argument('rastid', type=str, nargs='+', 
				help="One or more MG-RAST project identifiers (mgp####)")
	parser_rast.add_argument('-o', dest="outdir", type=str, default="",
				help="directory in which to save output. created if it doesn't exist")
	parser_rast.add_argument('-m', dest="metadata", action="store_true",
				help="save metadata")
	parser_rast.add_argument('-f', dest="force", action="store_true",
				help = "force re-download of files")
	parser_rast.add_argument('-t',dest="threads", type=int, default=1,
				help="threads to use (for pigz)")
	parser_rast.add_argument('-r',dest="retries", type=int, default=0,
				help="number of times to retry download")

	args = parser.parse_args()

	# Make output directories if they don't exist
	try:
		if args.outdir != "":
			if not os.path.exists(args.outdir):
				os.makedirs(args.outdir)
	except AttributeError: # No args were provided
		print("Subcommand not specified, run `grabseqs -h` or  `grabseqs sra -h` for help")
		sys.exit(0)
	try:
		if args.rastid:
			for rast_proj in args.rastid:
				target_list = get_mgrast_acc_metadata(rast_proj, args.metadata, args.outdir)
				print(target_list)
				for target in target_list:
					download_mgrast_sample(target, args.retries, args.threads, args.outdir, args.force)
	except AttributeError:
		for sra_identifier in args.id:
			acclist = get_sra_acc_metadata(sra_identifier, args.metadata, args.outdir)

			for acc in acclist:
				run_fasterq_dump(acc, args.retries, args.threads, args.outdir, args.force)


